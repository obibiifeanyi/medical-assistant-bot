{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca34ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n",
    "\n",
    "class FAISSIndexTester:\n",
    "    def __init__(self, base_path: str = \".\"):\n",
    "        \"\"\"\n",
    "        Initialize the FAISS Index Tester\n",
    "        \n",
    "        Args:\n",
    "            base_path: Base directory containing the indices folder\n",
    "        \"\"\"\n",
    "        self.base_path = base_path\n",
    "        self.indices_path = os.path.join(base_path, \"indices\")\n",
    "        self.loaded_indices = {}\n",
    "        self.index_metadata = {}\n",
    "        \n",
    "    def load_index(self, index_name: str) -> bool:\n",
    "        \"\"\"\n",
    "        Load a FAISS index from disk\n",
    "        \n",
    "        Args:\n",
    "            index_name: Name of the index (without file extension)\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if successfully loaded, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            index_path = os.path.join(self.indices_path, f\"{index_name}.faiss\")\n",
    "            metadata_path = os.path.join(self.indices_path, f\"{index_name}_metadata.pkl\")\n",
    "            \n",
    "            # Load the FAISS index\n",
    "            if os.path.exists(index_path):\n",
    "                index = faiss.read_index(index_path)\n",
    "                self.loaded_indices[index_name] = index\n",
    "                print(f\"✓ Successfully loaded index: {index_name}\")\n",
    "                \n",
    "                # Try to load metadata if it exists\n",
    "                if os.path.exists(metadata_path):\n",
    "                    with open(metadata_path, 'rb') as f:\n",
    "                        self.index_metadata[index_name] = pickle.load(f)\n",
    "                    print(f\"✓ Loaded metadata for: {index_name}\")\n",
    "                \n",
    "                return True\n",
    "            else:\n",
    "                print(f\"✗ Index file not found: {index_path}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error loading index {index_name}: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def load_all_indices(self):\n",
    "        \"\"\"Load all FAISS indices found in the indices directory\"\"\"\n",
    "        if not os.path.exists(self.indices_path):\n",
    "            print(f\"✗ Indices directory not found: {self.indices_path}\")\n",
    "            return\n",
    "            \n",
    "        faiss_files = [f for f in os.listdir(self.indices_path) if f.endswith('.faiss')]\n",
    "        \n",
    "        if not faiss_files:\n",
    "            print(\"No FAISS index files found\")\n",
    "            return\n",
    "            \n",
    "        for faiss_file in faiss_files:\n",
    "            index_name = faiss_file.replace('.faiss', '')\n",
    "            self.load_index(index_name)\n",
    "    \n",
    "    def get_index_info(self, index_name: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Get detailed information about a loaded index\n",
    "        \n",
    "        Args:\n",
    "            index_name: Name of the index\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing index information\n",
    "        \"\"\"\n",
    "        if index_name not in self.loaded_indices:\n",
    "            return {\"error\": f\"Index {index_name} not loaded\"}\n",
    "            \n",
    "        index = self.loaded_indices[index_name]\n",
    "        \n",
    "        info = {\n",
    "            \"name\": index_name,\n",
    "            \"total_vectors\": index.ntotal,\n",
    "            \"dimension\": index.d,\n",
    "            \"is_trained\": index.is_trained,\n",
    "            \"metric_type\": \"L2\" if index.metric_type == faiss.METRIC_L2 else \"IP\",\n",
    "            \"index_type\": type(index).__name__\n",
    "        }\n",
    "        \n",
    "        # Add metadata if available\n",
    "        if index_name in self.index_metadata:\n",
    "            info[\"metadata\"] = self.index_metadata[index_name]\n",
    "            \n",
    "        return info\n",
    "    \n",
    "    def test_search(self, index_name: str, query_vector: Optional[np.ndarray] = None, \n",
    "                   k: int = 5) -> Dict:\n",
    "        \"\"\"\n",
    "        Test search functionality on an index\n",
    "        \n",
    "        Args:\n",
    "            index_name: Name of the index to test\n",
    "            query_vector: Query vector (if None, uses a random vector)\n",
    "            k: Number of nearest neighbors to return\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing search results and performance metrics\n",
    "        \"\"\"\n",
    "        if index_name not in self.loaded_indices:\n",
    "            return {\"error\": f\"Index {index_name} not loaded\"}\n",
    "            \n",
    "        index = self.loaded_indices[index_name]\n",
    "        \n",
    "        # Generate random query vector if none provided\n",
    "        if query_vector is None:\n",
    "            query_vector = np.random.random((1, index.d)).astype('float32')\n",
    "            print(f\"Using random query vector of dimension {index.d}\")\n",
    "        else:\n",
    "            query_vector = query_vector.reshape(1, -1).astype('float32')\n",
    "            \n",
    "        try:\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Perform search\n",
    "            distances, indices = index.search(query_vector, k)\n",
    "            \n",
    "            search_time = time.time() - start_time\n",
    "            \n",
    "            results = {\n",
    "                \"search_time_ms\": search_time * 1000,\n",
    "                \"num_results\": len(indices[0]),\n",
    "                \"distances\": distances[0].tolist(),\n",
    "                \"indices\": indices[0].tolist(),\n",
    "                \"query_shape\": query_vector.shape\n",
    "            }\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Search failed: {str(e)}\"}\n",
    "    \n",
    "    def benchmark_index(self, index_name: str, num_queries: int = 100, k: int = 10) -> Dict:\n",
    "        \"\"\"\n",
    "        Benchmark search performance on an index\n",
    "        \n",
    "        Args:\n",
    "            index_name: Name of the index to benchmark\n",
    "            num_queries: Number of random queries to run\n",
    "            k: Number of nearest neighbors per query\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing benchmark results\n",
    "        \"\"\"\n",
    "        if index_name not in self.loaded_indices:\n",
    "            return {\"error\": f\"Index {index_name} not loaded\"}\n",
    "            \n",
    "        index = self.loaded_indices[index_name]\n",
    "        \n",
    "        # Generate random query vectors\n",
    "        query_vectors = np.random.random((num_queries, index.d)).astype('float32')\n",
    "        \n",
    "        try:\n",
    "            import time\n",
    "            \n",
    "            # Warmup\n",
    "            index.search(query_vectors[:5], k)\n",
    "            \n",
    "            # Benchmark\n",
    "            start_time = time.time()\n",
    "            distances, indices = index.search(query_vectors, k)\n",
    "            total_time = time.time() - start_time\n",
    "            \n",
    "            results = {\n",
    "                \"total_queries\": num_queries,\n",
    "                \"k\": k,\n",
    "                \"total_time_seconds\": total_time,\n",
    "                \"average_query_time_ms\": (total_time / num_queries) * 1000,\n",
    "                \"queries_per_second\": num_queries / total_time,\n",
    "                \"index_size\": index.ntotal\n",
    "            }\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Benchmark failed: {str(e)}\"}\n",
    "    \n",
    "    def compare_indices(self, query_vector: Optional[np.ndarray] = None, k: int = 5) -> Dict:\n",
    "        \"\"\"\n",
    "        Compare search results across all loaded indices\n",
    "        \n",
    "        Args:\n",
    "            query_vector: Query vector to use for comparison\n",
    "            k: Number of results to compare\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing comparison results\n",
    "        \"\"\"\n",
    "        if not self.loaded_indices:\n",
    "            return {\"error\": \"No indices loaded\"}\n",
    "            \n",
    "        # Use the first index's dimension if no query vector provided\n",
    "        first_index = next(iter(self.loaded_indices.values()))\n",
    "        if query_vector is None:\n",
    "            query_vector = np.random.random((1, first_index.d)).astype('float32')\n",
    "            \n",
    "        results = {}\n",
    "        for index_name in self.loaded_indices:\n",
    "            search_result = self.test_search(index_name, query_vector, k)\n",
    "            results[index_name] = search_result\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print a summary of all loaded indices\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FAISS INDICES SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if not self.loaded_indices:\n",
    "            print(\"No indices loaded\")\n",
    "            return\n",
    "            \n",
    "        for index_name in self.loaded_indices:\n",
    "            info = self.get_index_info(index_name)\n",
    "            print(f\"\\nIndex: {index_name}\")\n",
    "            print(f\"  Vectors: {info['total_vectors']:,}\")\n",
    "            print(f\"  Dimensions: {info['dimension']}\")\n",
    "            print(f\"  Type: {info['index_type']}\")\n",
    "            print(f\"  Trained: {info['is_trained']}\")\n",
    "            print(f\"  Metric: {info['metric_type']}\")\n",
    "            \n",
    "            if 'metadata' in info:\n",
    "                print(f\"  Metadata keys: {list(info['metadata'].keys())}\")\n",
    "\n",
    "\n",
    "# Example usage and testing functions\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate usage\"\"\"\n",
    "    \n",
    "    # Initialize the tester\n",
    "    tester = FAISSIndexTester()\n",
    "    \n",
    "    # Load your specific indices\n",
    "    print(\"Loading FAISS indices...\")\n",
    "    tester.load_index(\"faiss_severity_index_medibot\")\n",
    "    tester.load_index(\"faiss_symptom_index_medibot\")\n",
    "    \n",
    "    # Or load all indices in the directory\n",
    "    # tester.load_all_indices()\n",
    "    \n",
    "    # Print summary\n",
    "    tester.print_summary()\n",
    "    \n",
    "    # Test individual indices\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING SEARCH FUNCTIONALITY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for index_name in tester.loaded_indices:\n",
    "        print(f\"\\nTesting {index_name}:\")\n",
    "        result = tester.test_search(index_name, k=5)\n",
    "        if \"error\" not in result:\n",
    "            print(f\"  Search time: {result['search_time_ms']:.2f}ms\")\n",
    "            print(f\"  Results found: {result['num_results']}\")\n",
    "            print(f\"  Top distances: {result['distances'][:3]}\")\n",
    "        else:\n",
    "            print(f\"  Error: {result['error']}\")\n",
    "    \n",
    "    # Benchmark performance\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PERFORMANCE BENCHMARK\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for index_name in tester.loaded_indices:\n",
    "        print(f\"\\nBenchmarking {index_name}:\")\n",
    "        benchmark = tester.benchmark_index(index_name, num_queries=50)\n",
    "        if \"error\" not in benchmark:\n",
    "            print(f\"  Average query time: {benchmark['average_query_time_ms']:.2f}ms\")\n",
    "            print(f\"  Queries per second: {benchmark['queries_per_second']:.1f}\")\n",
    "        else:\n",
    "            print(f\"  Error: {benchmark['error']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
